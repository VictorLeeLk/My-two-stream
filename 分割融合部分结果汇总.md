### hmdb51训练结果

共6766个视频，共51类。

训练集:3570 

测试集:1530

- 光流图像
  u:6766个文件夹，  632599个文件(多出6766，主要是bin文件),       2.94GB
  v:6766个文件夹，   625833个文件，    2.81GB

#### **1、resnet101**

​     空域：49.412%

​     batch-size=25,lr=0.0005，

​    

| Epoch | Batch Time | Loss    | Prec@1                | Prec@5 |
| ----- | ---------- | ------- | --------------------- | ------ |
| 0     | 0.989      | 9.35553 | 27.908                | 60.915 |
| 1     | 0.3        | 8.99238 | 35.556                | 68.562 |
| 2     | 0.128      | 9.08418 | 38.366                | 73.203 |
| 3     | 0.038      | 9.69245 | 40.458                | 71.699 |
| 4     | 0.03       | 8.89487 | 41.569                | 74.248 |
| 5     | 0.03       | 8.70778 | 41.046                | 74.314 |
| 6     | 0.03       | 8.69555 | 41.503                | 75.49  |
| 7     | 0.03       | 8.71766 | 41.176                | 75.033 |
| 0     | 0.803      | 7.0113  | 38.954                | 69.346 |
| 1     | 0.102      | 7.53082 | 42.288                | 76.993 |
| 2     | 0.095      | 7.52079 | 46.863                | 78.366 |
| 3     | 0.095      | 7.16283 | 46.863                | 79.804 |
| 4     | 0.095      | 6.91466 | 47.843                | 80.131 |
| 5     | 0.095      | 6.9413  | 47.778                | 81.242 |
| 6     | 0.096      | 7.15054 | 48.17                 | 80.261 |
| 7     | 0.096      | 7.22314 | 48.562                | 79.542 |
| 8     | 0.096      | 7.05873 | 48.954                | 80.523 |
| 9     | 0.096      | 7.05607 | 47.647                | 80.196 |
| 10    | 0.095      | 7.26631 | 47.451                | 80.458 |
| 11    | 0.096      | 7.15514 | 48.039                | 80.327 |
| 12    | 0.096      | 7.17597 | 48.693                | 80.915 |
| 13    | 0.096      | 7.0335  | 48.431                | 80.654 |
| 14    | 0.096      | 6.96587 | 49.085                | 80.588 |
| 15    | 0.095      | 7.19063 | 48.039                | 80.327 |
| 16    | 0.096      | 6.90387 | 48.954                | 80.654 |
| 17    | 0.095      | 6.91702 | $\color{red}{49.412}$ | 80.654 |
| 18    | 0.095      | 7.07989 | 48.693                | 80.065 |
| 19    | 0.095      | 7.01262 | 48.039                | 80.327 |
| 20    | 0.095      | 7.06909 | 49.15                 | 80.458 |
| 21    | 0.096      | 7.00155 | 48.824                | 80.392 |
| 22    | 0.096      | 7.01698 | 48.431                | 79.935 |
| 23    | 0.096      | 7.08057 | 47.647                | 80.065 |
| 24    | 0.096      | 7.29921 | 46.928                | 80.327 |
| 25    | 0.096      | 6.92035 | 49.15                 | 80.98  |
| 26    | 0.095      | 7.25185 | 48.301                | 80.196 |
| 27    | 0.096      | 6.84859 | 48.105                | 80.85  |
| 28    | 0.096      | 7.04573 | 48.627                | 80.065 |
| 29    | 0.096      | 6.97157 | 47.451                | 80     |
| 30    | 0.096      | 7.07528 | 48.627                | 80.392 |
| 31    | 0.096      | 7.00251 | 48.693                | 80.523 |
| 32    | 0.096      | 7.14364 | 47.974                | 80.261 |
| 33    | 0.096      | 6.99962 | 48.17                 | 80.915 |
| 34    | 0.095      | 7.0877  | 48.17                 | 80.131 |



- 时域

  batch-szie=32,lr=0.01

  最佳结果:45.229%

  | Batch Time | Loss    | Prec@1                | Prec@5 |
  | ---------- | ------- | --------------------- | ------ |
  | 1.151      | 8.43905 | 8.824                 | 26.732 |
  | 0.915      | 6.61661 | 17.582                | 45.948 |
  | 0.539      | 7.44664 | 17.647                | 47.582 |
  | 0.291      | 7.13993 | 21.699                | 48.889 |
  | 0.307      | 3.95285 | 40.85                 | 73.791 |
  | 0.266      | 4.11328 | 42.092                | 75.621 |
  | 0.275      | 4.20526 | 42.745                | 76.209 |
  | 0.248      | 4.25069 | 43.529                | 75.882 |
  | 0.262      | 4.25289 | 44.444                | 77.124 |
  | 0.238      | 4.23901 | 44.444                | 76.471 |
  | 0.246      | 4.20839 | 43.922                | 76.405 |
  | 0.298      | 4.17036 | 43.791                | 76.601 |
  | 0.241      | 4.2219  | 44.379                | 77.059 |
  | 0.233      | 4.28448 | 44.183                | 77.451 |
  | 0.262      | 4.29105 | 43.203                | 76.667 |
  | 0.266      | 4.19822 | 44.51                 | 76.993 |
  | 0.387      | 4.17428 | 43.987                | 76.601 |
  | 0.211      | 4.22195 | 43.464                | 76.601 |
  | 0.222      | 4.24746 | 44.183                | 76.797 |
  | 0.229      | 4.13884 | $\color{red}{45.229}$ | 77.059 |
  | 0.242      | 4.23433 | 44.118                | 76.667 |
  | 0.24       | 4.22009 | 44.314                | 76.863 |
  | 0.28       | 4.18799 | 43.987                | 76.536 |
  | 0.232      | 4.17857 | 44.118                | 76.601 |
  | 0.271      | 4.35036 | 43.464                | 76.732 |
  | 0.231      | 4.18314 | 44.51                 | 76.471 |
  | 0.307      | 4.20926 | 43.595                | 76.34  |
  | 0.285      | 4.30045 | 44.641                | 76.732 |
  | 0.256      | 4.30747 | 43.922                | 76.601 |
  | 0.262      | 4.30495 | 43.464                | 76.471 |
  | 0.246      | 4.17434 | 44.575                | 76.536 |
  | 0.264      | 4.20346 | 44.51                 | 77.059 |
  | 0.256      | 4.25772 | 44.248                | 76.928 |
  | 0.22       | 4.23359 | 44.575                | 76.797 |
  | 0.237      | 4.22483 | 44.379                | 76.797 |



| 融合策略    | top1    | top2    |
| ------- | ------- | ------- |
| 均值      | 59.0865 | 88.366  |
| max     | 50.2601 | 84.9020 |
| 空域2，时域1 | 55.4248 | 86.4052 |
| 空域1，时域2 | 60.3922 | 88.4967 |





当把batch-size设置为64时

```
THCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1503961620703/work/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory
Traceback (most recent call last):
  File "spatial_cnn_hmdb51.py", line 283, in <module>
    main()
  File "spatial_cnn_hmdb51.py", line 76, in main
    model.run()
  File "spatial_cnn_hmdb51.py", line 124, in run
    self.train_1epoch()
  File "spatial_cnn_hmdb51.py", line 174, in train_1epoch
    output += self.model(input_var)
  File "/home/victorleelk/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.py", line 224, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/victorleelk/two-stream-from-github/two-stream-hmdb51/network.py", line 150, in forward
    x = self.layer1(x)
  File "/home/victorleelk/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.py", line 224, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/victorleelk/anaconda2/lib/python2.7/site-packages/torch/nn/modules/container.py", line 67, in forward
    input = module(input)
  File "/home/victorleelk/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.py", line 224, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/victorleelk/two-stream-from-github/two-stream-hmdb51/network.py", line 91, in forward
    out = self.conv3(out)
  File "/home/victorleelk/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.py", line 224, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/victorleelk/anaconda2/lib/python2.7/site-packages/torch/nn/modules/conv.py", line 254, in forward
    self.padding, self.dilation, self.groups)
  File "/home/victorleelk/anaconda2/lib/python2.7/site-packages/torch/nn/functional.py", line 52, in conv2d
    return f(input, weight, bias)
RuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1503961620703/work/torch/lib/THC/generic/THCStorage.cu:66
```







#### 2、resnet18时域

```
CUDA_VISIBLE_DEVICES=0 python motion_cnn.py 

batch_size=32, epochs=500, evaluate=False, lr=0.01, resume='', start_epoch=0
#没有进行时域分割，num_workers=4
```



| Epoch | Batch Time | Data Time | Loss    | Prec@1  | Prec@5  | lr         |
| ----- | ---------- | --------- | ------- | ------- | ------- | ---------- |
| 0     | 2.156      | 0.966     | 4.04733 | 3.8936  | 17.1989 | 0.01       |
| 0     | 2.531      | 1.327     | 4.04317 | 3.0252  | 15.4342 | 0.01       |
| 0     | 2.006      | 0.802     | 4.02932 | 4.5098  | 17.395  | 0.01       |
| 1     | 1.013      | 0.948     | 3.5816  | 10.9524 | 31.5126 | 0.01       |
| 2     | 0.927      | 0.864     | 3.27147 | 16.5266 | 43.6975 | 0.01       |
| 3     | 0.847      | 0.773     | 2.78582 | 27.0588 | 57.2549 | 0.001      |
| 4     | 0.843      | 0.769     | 2.58033 | 32.2409 | 62.7731 | 0.001      |
| 5     | 0.835      | 0.767     | 2.47727 | 33.2213 | 66.3585 | 0.001      |
| 6     | 0.849      | 0.785     | 2.3993  | 35.7983 | 67.8711 | 0.001      |
| 7     | 0.873      | 0.807     | 2.30355 | 37.9832 | 69.916  | 0.001      |
| 8     | 0.843      | 0.777     | 2.25833 | 39.5798 | 71.1204 | 0.001      |
| 9     | 0.828      | 0.76      | 2.17259 | 41.2045 | 72.7451 | 0.001      |
| 10    | 0.846      | 0.783     | 2.10776 | 43.6415 | 73.9776 | 0.001      |
| 11    | 0.811      | 0.741     | 2.02335 | 47.0028 | 75.9104 | 0.0001     |
| 12    | 0.8        | 0.735     | 1.97809 | 47.479  | 77.7311 | 0.0001     |
| 13    | 0.791      | 0.722     | 1.97294 | 47.2829 | 77.563  | 0.0001     |
| 14    | 0.828      | 0.768     | 1.96344 | 47.563  | 77.1429 | 0.0001     |
| 15    | 1.071      | 1         | 1.94458 | 48.8796 | 76.7787 | 0.00001    |
| 16    | 0.869      | 0.799     | 1.94721 | 47.2269 | 77.0028 | 0.00001    |
| 17    | 0.868      | 0.8       | 1.91678 | 49.2437 | 77.535  | 0.000001   |
| 18    | 0.795      | 0.73      | 1.93605 | 48.5714 | 77.0028 | 0.000001   |
| 19    | 0.794      | 0.735     | 1.92688 | 48.2633 | 78.1232 | 0.000001   |
| 20    | 0.831      | 0.763     | 1.93783 | 47.8431 | 77.8151 | 0.000001   |
| 21    | 0.744      | 0.681     | 1.93519 | 48.7395 | 77.619  | 0.0000001  |
| 22    | 0.754      | 0.69      | 1.93775 | 49.1036 | 77.2549 | 0.0000001  |
| 23    | 0.757      | 0.694     | 1.93101 | 47.7031 | 77.7591 | 0.00000001 |
| 24    | 0.788      | 0.724     | 1.92638 | 48.0112 | 77.8992 | 0.00000001 |
| 25    | 0.773      | 0.706     | 1.93195 | 48.5994 | 77.9272 | 0.00000001 |
| 26    | 0.749      | 0.687     | 1.93813 | 48.6835 | 78.1513 | 0.00000001 |
| 27    | 0.759      | 0.692     | 1.91716 | 49.4958 | 78.0672 | 0.00000001 |
| 28    | 0.735      | 0.668     | 1.94543 | 49.1597 | 77.2269 | 0.00000001 |
| 29    | 0.776      | 0.709     | 1.9421  | 47.8992 | 76.9748 | 0.00000001 |
| 30    | 0.745      | 0.68      | 1.92276 | 48.4034 | 78.1513 | 0.00000001 |
| 31    | 0.749      | 0.681     | 1.95783 | 47.3389 | 77.0028 | 0.00000001 |
| 32    | 0.716      | 0.648     | 1.92694 | 48.1232 | 76.7507 | 0.00000001 |
| 33    | 0.791      | 0.715     | 1.91838 | 49.4958 | 77.8151 | 0.00000001 |
| 34    | 0.754      | 0.687     | 1.95836 | 47.8151 | 76.7507 | 0.00000001 |
| 35    | 0.748      | 0.686     | 1.95408 | 48.2913 | 76.7227 | 0.00000001 |
| 36    | 0.752      | 0.676     | 1.95029 | 47.3669 | 77.6751 | 0.00000001 |
| 37    | 0.785      | 0.717     | 1.93614 | 48.8796 | 78.0672 | 0.00000001 |





- 测试集合

| Epoch | Batch Time | Loss    | Prec@1                | Prec@5 |
| ----- | ---------- | ------- | --------------------- | ------ |
| 0     | 0.655      | 7.23786 | 7.516                 | 23.464 |
| 1     | 0.252      | 7.84593 | 11.242                | 28.627 |
| 2     | 0.192      | 7.4333  | 13.529                | 39.412 |
| 3     | 0.207      | 4.67563 | 31.895                | 65.163 |
| 4     | 0.193      | 4.88513 | 33.464                | 68.562 |
| 5     | 0.224      | 4.66502 | 34.444                | 66.863 |
| 6     | 0.204      | 4.57741 | 36.275                | 69.477 |
| 7     | 0.207      | 4.54546 | 36.275                | 71.242 |
| 8     | 0.202      | 4.35964 | 38.824                | 72.549 |
| 9     | 0.229      | 4.49506 | 37.516                | 72.353 |
| 10    | 0.199      | 4.37555 | 38.758                | 72.876 |
| 11    | 0.216      | 4.23831 | 40.458                | 73.464 |
| 12    | 0.2        | 4.22788 | 40.458                | 74.379 |
| 13    | 0.223      | 4.25943 | 40.784                | 73.987 |
| 14    | 0.195      | 4.29885 | 40.327                | 74.183 |
| 15    | 0.204      | 4.22757 | 40.98                 | 74.183 |
| 16    | 0.188      | 4.28803 | 41.046                | 73.922 |
| 17    | 0.193      | 4.24145 | 40.915                | 74.183 |
| 18    | 0.213      | 4.176   | 41.242                | 74.444 |
| 19    | 0.218      | 4.22205 | 41.176                | 74.379 |
| 20    | 0.195      | 4.25608 | 41.176                | 73.987 |
| 21    | 0.217      | 4.29323 | 40.85                 | 74.314 |
| 22    | 0.215      | 4.18256 | 40.261                | 73.66  |
| 23    | 0.193      | 4.21453 | 40.392                | 74.641 |
| 24    | 0.201      | 4.19661 | 41.111                | 74.51  |
| 25    | 0.198      | 4.26151 | 40.458                | 73.987 |
| 26    | 0.199      | 4.21891 | 40.915                | 73.987 |
| 27    | 0.194      | 4.20866 | 40.915                | 74.314 |
| 28    | 0.222      | 4.19577 | 40.85                 | 74.118 |
| 29    | 0.206      | 4.25268 | 40.85                 | 73.856 |
| 30    | 0.22       | 4.23854 | 40.458                | 74.118 |
| 31    | 0.195      | 4.19427 | 40.719                | 73.922 |
| 32    | 0.208      | 4.1946  | 41.373                | 74.248 |
| 33    | 0.202      | 4.15377 | 41.373                | 74.052 |
| 34    | 0.223      | 4.26417 | 40.784                | 74.183 |
| 35    | 0.208      | 4.17396 | 40.85                 | 74.51  |
| 36    | 0.207      | 4.2029  | $\color{red}{41.503}$ | 74.379 |
| 37    | 0.188      | 4.18492 | 41.176                | 74.118 |

--------------------------------------









> ### Date:0404-0410

#### resnet101时域、分割HMDB51视频片段

其batch-size=32,lr=0.01

在取三个分割，识别**最后一个分割中**堆叠光流，其结果如下:

最佳结果为$\color{red}{38.954}$,比第一个分割45.229%差6%。

| 0    | 1.525 | 8.38807  | 11.307 | 34.51  |
| ---- | ----- | -------- | ------ | ------ |
| 1    | 1.68  | 6.8851   | 17.059 | 44.444 |
| 2    | 1.25  | 10.08754 | 16.667 | 41.438 |
| 3    | 1.587 | 7.02737  | 25.163 | 58.105 |
| 4    | 1.64  | 4.95218  | 36.209 | 70.065 |
| 5    | 1.226 | 5.06429  | 36.013 | 71.046 |
| 6    | 1.608 | 5.04817  | 36.013 | 70.654 |
| 7    | 1.711 | 4.88648  | 37.386 | 69.804 |
| 8    | 1.576 | 4.83852  | 38.105 | 72.026 |
| 9    | 1.409 | 4.81813  | 37.909 | 70.719 |
| 10   | 1.531 | 4.88157  | 37.974 | 71.111 |
| 11   | 1.602 | 4.77611  | 38.366 | 72.353 |
| 12   | 1.395 | 4.82632  | 37.974 | 71.111 |
| 13   | 1.631 | 4.871    | 37.778 | 71.569 |
| 14   | 1.348 | 4.83769  | 38.235 | 72.418 |
| 15   | 1.365 | 4.90355  | 37.451 | 70.654 |
| 16   | 1.651 | 4.79131  | 38.431 | 72.549 |
| 17   | 1.091 | 4.75848  | 38.301 | 72.288 |
| 18   | 1.614 | 4.79951  | 38.954 | 71.046 |
| 19   | 1.627 | 4.85866  | 37.974 | 72.092 |
| 20   | 1.499 | 4.78303  | 38.17  | 71.307 |







- 采用三个分割融合的结果

  batch-size=64,lr=0.01

  其最佳结果为43.072%，低于第一个分割的45.229%，好于第3个分割的38.954

  > 说明三个分割的结果并不一定会对性能有所提升，这个和每一个分割的识别结果有关，有些分割对整体性能影响较大，有些则影响较小，需要将每一个分割的重要性依据其对视频类别的重要性设置一个权重。

  | 0    | 3.827 | 12.38562 | 1.307  | 9.935  |
  | ---- | ----- | -------- | ------ | ------ |
  | 1    | 4.472 | 18.2615  | 3.464  | 13.791 |
  | 2    | 4.029 | 5.19106  | 6.536  | 20.915 |
  | 3    | 4.442 | 4.3256   | 6.209  | 25.163 |
  | 4    | 4.274 | 4.33101  | 9.477  | 30.784 |
  | 5    | 4.116 | 3.7579   | 14.575 | 44.248 |
  | 6    | 3.685 | 3.66917  | 18.17  | 45.098 |
  | 7    | 3.929 | 3.65021  | 22.222 | 53.66  |
  | 8    | 3.966 | 3.34903  | 23.464 | 59.412 |
  | 9    | 3.828 | 3.97053  | 22.81  | 55.163 |
  | 10   | 3.558 | 3.37947  | 29.346 | 61.895 |
  | 11   | 3.401 | 3.1718   | 39.15  | 71.046 |
  | 12   | 3.271 | 2.90553  | 39.673 | 72.876 |
  | 13   | 3.395 | 2.83801  | 39.673 | 72.68  |
  | 14   | 3.155 | 2.96263  | 40.85  | 73.072 |
  | 15   | 3.028 | 2.92253  | 42.026 | 73.203 |
  | 16   | 3.92  | 3.10524  | 41.111 | 73.072 |
  | 17   | 3.746 | 3.05388  | 42.745 | 73.203 |
  | 18   | 3.997 | 3.06849  | 41.895 | 73.529 |
  | 19   | 3.834 | 3.12425  | 42.157 | 72.941 |
  | 20   | 3.664 | 3.13676  | 41.699 | 73.399 |
  | 21   | 3.498 | 3.09559  | 41.83  | 72.745 |
  | 22   | 4.799 | 3.09683  | 42.549 | 73.529 |
  | 23   | 2.906 | 3.03007  | 42.418 | 73.268 |
  | 24   | 2.539 | 3.09516  | 41.634 | 73.464 |
  | 25   | 2.426 | 3.02204  | 41.83  | 73.856 |
  | 26   | 2.346 | 3.03967  | 42.484 | 73.464 |
  | 27   | 2.246 | 3.09017  | 41.83  | 73.399 |
  | 28   | 3.271 | 3.1143   | 42.484 | 73.399 |
  | 29   | 2.231 | 3.08538  | 42.288 | 73.399 |
  | 30   | 2.797 | 3.12911  | 42.288 | 73.595 |
  | 31   | 3.326 | 3.09971  | 42.157 | 72.876 |
  | 32   | 3.963 | 3.08762  | 42.549 | 73.137 |
  | 33   | 3.182 | 3.09669  | 42.353 | 73.072 |
  | 34   | 4.282 | 3.10981  | 42.157 | 73.137 |
  | 35   | 2.369 | 3.03807  | 41.895 | 73.072 |
  | 36   | 3.648 | 3.04919  | 42.092 | 73.072 |
  | 37   | 3.856 | 3.04885  | 42.353 | 73.072 |
  | 38   | 3.642 | 3.09985  | 41.765 | 73.268 |
  | 39   | 2.816 | 3.21589  | 42.288 | 73.203 |
  | 40   | 3.13  | 3.03364  | 42.353 | 72.68  |
  | 41   | 2.166 | 3.15268  | 42.026 | 72.941 |
  | 42   | 3.107 | 3.08193  | 43.072 | 73.529 |
  | 43   | 3.006 | 3.17193  | 42.745 | 73.464 |
  | 44   | 1.86  | 3.08704  | 41.83  | 73.529 |
  | 45   | 1.829 | 3.159    | 41.699 | 73.333 |
  | 46   | 1.74  | 3.10825  | 42.026 | 73.268 |
  | 47   | 1.791 | 3.0524   | 43.007 | 72.81  |
  | 48   | 1.747 | 3.16575  | 41.765 | 73.856 |
  | 49   | 2.146 | 3.13049  | 41.438 | 74.248 |










##### resnet18时域分割均值融合训练测试结果

`参数设置：`

> batch-size =25
>
> lr=0.01
>
> num-workers=4
>
> hmdb_split='2'  #采用Hmdb51 分割方案2

`运行： CUDA_VISIBLE_DEVICES=0 python motion_cnn_hmdb51.py `

经过60个epoch，长达12小时训练，其学习速率已经下降到LR=1e-08,其结果并未收敛，损失也未下降过多。

其部分结果如下：

```
==> Epoch:[59/500][training stage]
100%|█████████████████████████████████████████| 143/143 [06:54<00:00,  2.90s/it]
Time [2.9] Data [2.702] 
Loss [3.76496] Prec@1 [4.5658] Prec@5 [19.2157]
LR 1e-08
==> Epoch:[59/500][validation stage]
100%|█████████████████████████████████████████| 306/306 [07:02<00:00,  1.38s/it]
Time [1.381] 
Loss [4.46496] Prec@1 [4.575] Prec@5 [17.516] 
```



#### resnet18时域分割最大值训练测试

`参数设置：`

>batch-size =64
>
>lr=0.01
>
>num-workers=0
>
>hmdb_split='2'  #采用Hmdb51 分割方案2

经过78个epoch，每一个eoch数据读取、训练和测试共达到17分钟，总共长达22个小时。训练准确率14.5%左右震荡，测试准确率在11.5%左右震荡。

训练集和测试集在第6个epoch时出现较大性能提升，之后准确率处于震荡状态。

`训练集`

| 4    | 10.26 | 9.982 | 3.79711 | 6.8347  | 18.4034 | 0.01  |
| ---- | ----- | ----- | ------- | ------- | ------- | ----- |
| 5    | 9.628 | 9.35  | 3.75472 | 7.9832  | 19.972  | 0.01  |
| 6    | 9.202 | 8.925 | 3.67652 | 10.4202 | 22.577  | 0.01  |
| 7    | 9.534 | 9.258 | 3.58124 | 13.1933 | 24.0336 | 0.001 |
| 8    | 9.274 | 8.998 | 3.54691 | 13.9216 | 24.5658 | 0.001 |

`测试集`

| 4    | 3.698 | 8.36993  | 6.993  | 17.712 |
| ---- | ----- | -------- | ------ | ------ |
| 5    | 3.693 | 10.67336 | 6.797  | 18.693 |
| 6    | 3.759 | 11.09684 | 11.111 | 22.222 |
| 7    | 3.759 | 9.47021  | 10.98  | 22.288 |
| 8    | 4.243 | 9.20674  | 11.438 | 23.137 |





#### 在ucf101采用resnet18 进行最大值融合讨论

```
CUDA_VISIBLE_DEVICES=0 python spatial_cnn.py 
Namespace(batch_size=25, epochs=500, evaluate=False, lr=0.0005, resume='', start_epoch=0)
```



在经过26个epoch训练，每个epoch53分钟左右，共约24小时训练

在第25个epoch时，此时学习速率达到5e-9，学习正确率达到69.046%

==> Epoch:[25/500][training stage]
100%|█████████████████████████████████████████| 382/382 [33:49<00:00,  5.31s/it]
Time [5.313] Data [5.218] 
Loss [0.40361] Prec@1 [93.5724] Prec@5 [95.8268]
LR 5e-09

==> Epoch:[25/500][validation stage]
100%|███████████████████████████████████████| 2876/2876 [19:38<00:00,  2.44it/s]
Time [0.41] 
Loss [11.46529] Prec@1 [69.046] Prec@5 [88.369] 

之前采用均值的情况下，其效果达到了**73.883%**。

> 说明分割片段取均值效果好于去最大值。



#### ucf101 时域resnet18基于方差加权融合方案

视频分成3个片段，每一个片段对行为的重要性不是一样的，所以考虑给每一个分割的输出特征（预测）赋予一定权重。

>  基本依据：重要性越大的片段，其对最终的准确率贡献越大。在分割片段预测的特征表现上，主要是在正确预测的位置其特征值(概率值)越大，而在其他类别预测概率值越小。因此一般情况下，重要性越大的片段其预测的结果101类别数值约离散，考虑采用方差来进行加权求和。

当前训练，每个epoch训练时间达到4个小时，目前经过两个epoch，其测试准确率为20%左右。



- 问题汇总

  1、当前单个第三个分割识别效果低于随机取10帧的结果。考虑分别识别前两个分割的效果。

  2、分割融合方案，存在每次融合再进行识别准确率的计算，时间代价较长，考虑保存后面训练epoch的结果进行离线融合

  ​







**pytorch softmax函数**

对n维输入张量运用Softmax函数，将张量的每个元素缩放到（0,1）区间且和为1。Softmax函数定义如下：

$$f_i(x) = \frac{e^{(x_i - shift)}} { \sum^j e^{(x_j - shift)}},shift = max (x_i)$$

shape：

- 输入：(N, L)
- 输出：(N, L)

返回结果是一个与输入维度相同的张量，每个元素的取值范围在（0,1）区间。

例子：

```
>>> m = nn.Softmax()
>>> input = autograd.Variable(torch.randn(2, 3))
>>> print(input)
>>> print(m(input))
```

## Linear layers

```
class torch.nn.Linear(in_features, out_features, bias=True)
```

对输入数据做线性变换：\(y = Ax + b\)

**参数：**

- **in_features** - 每个输入样本的大小
- **out_features** - 每个输出样本的大小
- **bias** - 若设置为False，这层不会学习偏置。默认值：True

**形状：**

- **输入:** \((N, in\_features)\)
- **输出：** \((N, out\_features)\)

**变量：**

- **weight** -形状为(out_features x in_features)的模块中可学习的权值
- **bias** -形状为(out_features)的模块中可学习的偏置

**例子：**

```
>>> m = nn.Linear(20, 30)
>>> input = autograd.Variable(torch.randn(128, 20))
>>> output = m(input)
>>> print(output.size())
```

## Distance functions

```
class torch.nn.PairwiseDistance(p=2, eps=1e-06)
```

按批计算向量v1, v2之间的距离：

$$\Vert x \Vert _p := \left( \sum_{i=1}^n \vert x_i \vert ^ p \right) ^ {1/p}$$

**参数：**

- **x** (*Tensor*): 包含两个输入batch的张量
- **p** (real): 范数次数，默认值：2

**形状：**

- **输入：** \((N, D)\)，其中D=向量维数
- **输出：** \((N, 1)\)

```
>>> pdist = nn.PairwiseDistance(2)
>>> input1 = autograd.Variable(torch.randn(100, 128))
>>> input2 = autograd.Variable(torch.randn(100, 128))
>>> output = pdist(input1, input2)
```

### class torch.nn.CrossEntropyLoss(weight=None, size_average=True)[[source\]](http://pytorch.org/docs/_modules/torch/nn/modules/loss.html#CrossEntropyLoss)

此标准将`LogSoftMax`和`NLLLoss`集成到一个类中。

当训练一个多类分类器的时候，这个方法是十分有用的。

- weight(tensor): `1-D` tensor，`n`个元素，分别代表`n`类的权重，如果你的训练样本很不均衡的话，是非常有用的。默认值为None。

调用时参数：

- input : 包含每个类的得分，`2-D` tensor,`shape`为 `batch*n`
- target: 大小为 `n` 的 `1—D` `tensor`，包含类别的索引(`0到 n-1`)。

Loss可以表述为以下形式： $$ \begin{aligned} loss(x, class) &= -\text{log}\frac{exp(x[class])}{\sum_j exp(x[j]))}\ &= -x[class] + log(\sum_j exp(x[j])) \end{aligned} $$ 当`weight`参数被指定的时候，`loss`的计算公式变为： $$ loss(x, class) = weights[class] * (-x[class] + log(\sum_j exp(x[j]))) $$ 计算出的`loss`对`mini-batch`的大小取了平均。

形状(`shape`)：

- Input: (N,C) `C` 是类别的数量
- Target: (N) `N`是`mini-batch`的大小，0 <= targets[i] <= C-1

`torch.``var`()

- `torch.``var`(*input*, *unbiased=True*) → float


Returns the variance of all elements in the `input` tensor.

If `unbiased` is `False`, then the variance will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used.

| Parameters: | **input** ([*Tensor*](http://pytorch.org/docs/stable/tensors.html#torch.Tensor)) – the input tensor**unbiased** ([*bool*](https://docs.python.org/2/library/functions.html#bool)) – whether to use the unbiased estimation or not |
| ----------- | ---------------------------------------- |
|             |                                          |

Example:

```
>>> a = torch.randn(1, 3)
>>> a

-1.3063  1.4182 -0.3061
[torch.FloatTensor of size 1x3]

>>> torch.var(a)
1.899527506513334
```

- `torch.``var`(*input*, *dim*, *keepdim=False*, *unbiased=True*, *out=None*) → Tensor


Returns the variance of each row of the `input` tensor in the given dimension `dim`.

If `keepdim` is `True`, the output tensors are of the same size as `input` except in the dimension `dim`where they are of size 1. Otherwise, `dim` is squeezed (see [`torch.squeeze()`](http://pytorch.org/docs/stable/torch.html#torch.squeeze)), resulting in the outputs tensor having 1 fewer dimension than `input`.

If `unbiased` is `False`, then the variance will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used.

| Parameters: | **input** ([*Tensor*](http://pytorch.org/docs/stable/tensors.html#torch.Tensor)) – the input tensor**dim** ([*int*](https://docs.python.org/2/library/functions.html#int)) – the dimension to reduce**keepdim** ([*bool*](https://docs.python.org/2/library/functions.html#bool)) – whether the output tensor has `dim` retained or not**unbiased** ([*bool*](https://docs.python.org/2/library/functions.html#bool)) – whether to use the unbiased estimation or not**out** ([*Tensor*](http://pytorch.org/docs/stable/tensors.html#torch.Tensor)*, **optional*) – the output tensor |
| ----------- | ---------------------------------------- |
|             |                                          |

Example:

```
>>> a = torch.randn(4, 4)
>>> a

-1.2738 -0.3058  0.1230 -1.9615
 0.8771 -0.5430 -0.9233  0.9879
 1.4107  0.0317 -0.6823  0.2255
-1.3854  0.4953 -0.2160  0.2435
[torch.FloatTensor of size 4x4]

>>> torch.var(a, 1)

 0.8859
 0.9509
 0.7548
 0.6949
[torch.FloatTensor of size 4]
```